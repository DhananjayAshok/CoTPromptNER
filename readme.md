Ideas of investigation:

1. Chain of Thought Features:
    
* Negative Exemplars? Very likely not
* Explicitly asking it to calculate and report important quantities? Is clearly better
* Telling it to consider important quantities instead of giving them? Basically the same
* Can LLMs learn to make a plan? Similar to subquestion to design but maybe is different?

2. Can we apply cot prompting to NLVU 3 squares dataset by partitioning the three areas